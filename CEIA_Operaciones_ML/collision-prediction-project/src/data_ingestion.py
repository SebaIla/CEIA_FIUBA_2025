# Importa librer√≠as necesarias para hacer peticiones HTTP, manejar JSON, controlar tiempos, manipular datos y rutas de archivos
import requests
import json
import time
import pandas as pd
from pathlib import Path

# Funci√≥n principal para obtener datos de colisiones desde la API de Los √Ångeles
def fetch_collision_data():
    # URL del endpoint de la API p√∫blica
    api_ep_la_collisions = 'https://data.lacity.org/resource/d5tf-ez2w.json'
    
    # Par√°metros de configuraci√≥n para la descarga
    LIMIT = 50000               # N√∫mero m√°ximo de registros por petici√≥n
    MAX_RETRIES = 3             # N√∫mero m√°ximo de reintentos en caso de error
    RETRY_DELAY = 10            # Tiempo de espera entre reintentos (segundos)
    EXPECTED_TOTAL_ROWS = 621677  # N√∫mero esperado de registros totales

    # Inicializa variables para almacenar los datos y controlar el progreso
    la_collisions_data = []
    offset = 0
    total_retrieved = 0

    print("Starting data retrieval...")  # Mensaje inicial

    # Bucle principal para descargar los datos en bloques
    while True:
        retries = 0
        success = False
        last_error_message = ""

        # Bucle de reintentos en caso de fallos
        while retries < MAX_RETRIES and not success:
            try:
                # Define los par√°metros de la petici√≥n (limit y offset)
                params = {'$limit': LIMIT, '$offset': offset}
                response = requests.get(api_ep_la_collisions, params=params)

                # Si la respuesta es exitosa (HTTP 200)
                if response.status_code == 200:
                    chunk = response.json()  # Convierte la respuesta en JSON
                    la_collisions_data.extend(chunk)  # Agrega los datos al acumulador
                    retrieved = len(chunk)
                    total_retrieved += retrieved
                    print(f"‚úÖ Partially ingested {retrieved} rows (Total: {total_retrieved})")
                    offset += retrieved  # Actualiza el offset para la siguiente petici√≥n
                    success = True
                else:
                    # Si hay error HTTP, muestra mensaje y espera para reintentar
                    last_error_message = f"HTTP Error {response.status_code}: {response.text}"
                    print(f"‚ö†Ô∏è {last_error_message}. Retrying...")
                    retries += 1
                    if retries < MAX_RETRIES:
                        time.sleep(RETRY_DELAY)
            except Exception as e:
                # Si ocurre una excepci√≥n (por ejemplo, error de red)
                last_error_message = f"Exception: {str(e)}"
                print(f"‚ö†Ô∏è {last_error_message}. Retrying...")
                retries += 1
                if retries < MAX_RETRIES:
                    time.sleep(RETRY_DELAY)

        # Si no se logr√≥ obtener datos despu√©s de varios intentos, se detiene
        if not success:
            print(f"‚ùå Failed after {MAX_RETRIES} attempts. Stopping. Last error: {last_error_message}")
            break

        # Si el bloque recibido tiene menos registros que el l√≠mite, significa que ya no hay m√°s datos
        if len(chunk) < LIMIT:
            break

    # Mensaje final con el total de registros obtenidos
    print(f"‚úÖ Final ingestion completed: {len(la_collisions_data)} rows retrieved.")

    # Verifica si se obtuvo el n√∫mero esperado de registros
    if len(la_collisions_data) == EXPECTED_TOTAL_ROWS:
        print(f"üéâ Successfully retrieved all {EXPECTED_TOTAL_ROWS} expected rows.")
    else:
        print(f"‚ùó Warning: Expected {EXPECTED_TOTAL_ROWS} rows, but retrieved {len(la_collisions_data)} rows.")
    
    return la_collisions_data  # Devuelve los datos obtenidos

# Funci√≥n para guardar los datos en un archivo JSON
def save_raw_data(data, output_path):
    # Crea el directorio si no existe
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    # Guarda los datos en formato JSON
    with open(output_path, 'w') as f:
        json.dump(data, f)
    
    print(f"Data saved to {output_path}")  # Mensaje de confirmaci√≥n

# Punto de entrada del script
if __name__ == "__main__":
    data = fetch_collision_data()  # Obtiene los datos
    save_raw_data(data, "data/raw/la_collisions_raw.json")  # Los guarda en disco